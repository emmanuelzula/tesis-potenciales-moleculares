{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Arquitectura Transformers </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema sobre el cual la artquitectura aprenderá: Propiedades Moleculares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"imagenes/potencial1.png\" alt=\"Potencial Molecular\" width=\"300\" style=\"margin-right: 10px;\">\n",
    "  <img src=\"imagenes/potencial2.png\" alt=\"Potencial Molecular\" width=\"300\" style=\"margin-right: 10px;\">\n",
    "  <img src=\"imagenes/potencial3.png\" alt=\"Potencial Molecular\" width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Información sobre el tema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este trabajo, caracterizamos propiedades moleculares con la posición $\\vec{r}$ y número atómico $z$ de los atómos que la componen (Variable $\\bf X$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuantificación de esta información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cuenta con la estructura y propiedades de 130831 moleculas. La propiedad de interes (Variable $\\bf Y$) es la energía interna a $0K$ $(U_0)$. Los valores de $\\bf Y$ estan entre -19444.386 eV y -1101.487 eV\n",
    "\n",
    "Base de datos: \n",
    "\n",
    "[torch_geometric.datasets.qm9](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.datasets.QM9.html)    \n",
    "\n",
    "Articulos: \n",
    "\n",
    "[MoleculeNet: A Benchmark for Molecular Machine Learning](https://arxiv.org/abs/1703.00564) \n",
    "\n",
    "[Neural Message Passing for Quantum Chemistry](https://arxiv.org/abs/1704.01212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entorno de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchMD-NET es un a arquitectura de equivariant Transformer (ET) la cual debe ser instalada en un ambiente virtual con los siguientes modulos.\n",
    "\n",
    "**Dependencias:**\n",
    "- h5py\n",
    "- matplotlib\n",
    "- nnpops==0.5\n",
    "- pip\n",
    "- pytorch==2.0.*\n",
    "- pytorch_cluster==1.6.1\n",
    "- pytorch_geometric==2.3.1\n",
    "- pytorch_scatter==2.1.1\n",
    "- pytorch_sparse==0.6.17\n",
    "- pytorch-lightning==1.6.3\n",
    "- torchmetrics==0.11.4\n",
    "- tqdm\n",
    "\n",
    "**Herramientas de desarrollo:**\n",
    "- flake8\n",
    "- pytest\n",
    "- psutil\n",
    "- ninja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencias, herramientas de desarrollo y la arquitectura estan instaladas en un contenedor docker con nombre emmanuelzula/servicio:1.3 el cual puede ser descargado de [DockerHub](https://hub.docker.com/layers/emmanuelzula/servicio/1.3/images/sha256-6719a1f8ac3a8f45981b868b497c43f64df60da1d56a9a9122fecd9b522b6f39?context=repo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación y procesamiento de los datos en la artquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchMD-NET tiene un modulo especializado en descargar y procesar el dataset QM9 el cual se encuentra en: \n",
    "\n",
    "torchmd-net/torchmdnet/datasets/qm9.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de datos QM9 (Quantum Chemistry for Machine Learning). QM9 es una base de datos ampliamente utilizada en la química computacional y el aprendizaje automático para la predicción de propiedades moleculares. Contiene información sobre una amplia variedad de moléculas orgánicas pequeñas y sus propiedades calculadas mediante cálculos de química cuántica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga y procesamiento del dataset para su analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/mambaforge/envs/torchmd-net/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://data.pyg.org/datasets/qm9_v3.zip\n",
      "Extracting data/raw/qm9_v3.zip\n",
      "Using a pre-processed version of the dataset. Please install 'rdkit' to alternatively process the raw data.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from scripts.qm9 import QM9\n",
    "\n",
    "# Crear una instancia de la clase QM9\n",
    "dataset = QM9(root='data', transform=None, label='energy_U0')\n",
    "\n",
    "dataset.download() # Descargar los datos\n",
    "\n",
    "dataset.process()   # Procesar los datos\n",
    "\n",
    "torch.save(dataset, '/workspace/clase_torchmd-net/data/dataset_qm9.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de datos QM9 consta de 130831 elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de muestras es: 130831\n"
     ]
    }
   ],
   "source": [
    "#Numero de muestras\n",
    "print(\"El número de muestras es: \" + str(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada muestra consta de propiedades de moleculas simples, las cuales son: x, edge_index, edge_attr, y, pos, idx, name y z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[5, 11], edge_index=[2, 8], edge_attr=[8, 4], y=[1, 1], pos=[5, 3], idx=[1], name='gdb_1', z=[5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]  # Acceder al primer elemento del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas claves son:\n",
    "\n",
    "1. `x`: Esta clave representa las características de los nodos en el grafo. En el contexto de la base de datos QM9, los nodos corresponden a átomos en una molécula. Por lo tanto, `x` contiene información sobre estos átomos. En este caso, hay 5 nodos (átomos) y cada uno tiene 11 características.\n",
    "\n",
    "2. `edge_index`: Esta clave almacena la información de conectividad en el grafo. Indica cómo los nodos (átomos) están conectados entre sí mediante enlaces químicos. En este caso, hay 2 filas (representando pares de nodos conectados) y 8 columnas, lo que sugiere que hay 8 enlaces químicos en esta molécula.\n",
    "\n",
    "3. `edge_attr`: Esta clave contiene atributos asociados a los bordes (enlaces químicos) del grafo. Hay 8 bordes en total, y cada borde tiene 4 características.\n",
    "\n",
    "4. `y`: Esta clave representa el valor de la energía interna total (U_0) para la molécula. En este caso, parece haber una única etiqueta con valor 1, que corresponde a la energía total de la molécula.\n",
    "\n",
    "5. `pos`: Esta clave contiene la posición tridimensional de los nodos en el espacio. En este caso, hay 5 nodos, y cada nodo tiene 3 coordenadas para su posición en el espacio tridimensional.\n",
    "\n",
    "6. `idx`: Esta clave indica un índice único asociado a este elemento en particular. Puede ser útil para rastrear o identificar específicamente este elemento en la base de datos.\n",
    "\n",
    "7. `name`: Esta clave generalmente almacena un nombre o identificador único para este elemento. En este caso, el nombre es \"gdb_1\".\n",
    "\n",
    "8. `z`: Esta clave representa el número atómico de los átomos en la molécula. Hay 5 valores en total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo solamente utiliza los valores de \"z\", \"pos\" y \"y\", tomando \"z\" y \"pos\" como nuestra $\\bf X$, en cambio tomanos \"y\" como nuestra $\\bf Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenidos de las entradas de nuestro interes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos un elemento del dataset\n",
    "elemento=dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La llave \"z\" contiene los numeros atómicos de los atómos que componen a la molécula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key x:\n",
      "tensor([6, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Key z:\\n{elemento.z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La llave \"pos\" contiene las posiciones de los atómos que componen a la molécula en armstrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key pos:\n",
      "tensor([[-1.2700e-02,  1.0858e+00,  8.0000e-03],\n",
      "        [ 2.2000e-03, -6.0000e-03,  2.0000e-03],\n",
      "        [ 1.0117e+00,  1.4638e+00,  3.0000e-04],\n",
      "        [-5.4080e-01,  1.4475e+00, -8.7660e-01],\n",
      "        [-5.2380e-01,  1.4379e+00,  9.0640e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Key pos:\\n{elemento.pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La llave \"y\" contiene la energía interna de la molécula una temperatura de $0K$ en eV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key y:\n",
      "tensor([[-1101.4878]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Key y:\\n{elemento.y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección aleatoria de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función \"train_val_test_split\" en el archivo \"torchmd-net/torchmdnet/utils.py\" linea 54. Crea 3 arrays aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de los datasets learn (train y validation) y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función \"make_splits\" en el archivo \"torchmd-net/torchmdnet/utils.py\" linea 112. Utiliza los arrays para guardar un array con los indices seleccionados para los dataset train, val y test\n",
    "\n",
    "La clase \"DataModule\" en el archivo \"torchmd-net/torchmdnet/data.py\" linea 90, 93 y 102. Crea los datasets train, val, y test\n",
    "\n",
    "Se define \"data\" con la clase \"DataModule\" en el archivo \"torchmd-net/torchmdnet/scripts/train.py\" linea 128. Se ejecuta el codigo antes descrito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de la arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase \"TorchMD_ET\" en el archivo \"torchmd-net/torchmdnet/models/torchmd_et.py\" linea 14. Define el modelo de transformer equivariante\n",
    "\n",
    "La función \"create_model\" en el archivo \"torchmd-net/torchmdnet/models/model.py\" linea 15. Procesa y selecciona el modelo \"TorchMD_ET\"\n",
    "\n",
    "La clase \"LNNP\" en el archivo \"torchmd-net/torchmdnet/module.py\" linea 12. Adapta el modelo creado para ser usado por pytorch_lightning\n",
    "\n",
    "Se define \"model\" con la clase \"LNNP\" en el archivo \"torchmd-net/torchmdnet/scripts/train.py\" linea 136. Se ejecuta el codigo antes descrito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define \"trainer\" en el archivo \"torchmd-net/torchmdnet/scripts/train.py\" linea 165. Compila el modelo construido\n",
    "\n",
    "Se ejecuta la instrucción \"trainer.fit(model, data)\" en el achivo \"torchmd-net/torchmdnet/scripts/train.py\" linea 179. Inicia el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rutas y paquterias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo metrics \n",
    "path_metric_csv = \"/workspace/tesis-potenciales-moleculares/output/metrics.csv\"\n",
    "\n",
    "path_splits_npy = \"/workspace/tesis-potenciales-moleculares/output/splits.npz\"\n",
    "\n",
    "# Ruta al dataset que uso torchmd-net\n",
    "path_torchmdnet_dataset = \"/workspace/tesis-potenciales-moleculares/data/dataset_qm9.pt\"\n",
    "\n",
    "# Ruta al modelo entrenado\n",
    "path_trained_model=\"/workspace/tesis-potenciales-moleculares/output/epoch=669-val_loss=0.0003-test_loss=0.0064.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar Modulos\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scripts.qm9 import QM9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestra de la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros datos\n",
      "   epoch        lr   train_loss  val_loss  step  test_loss\n",
      "0    0.0  0.000023  1444.552734  8.349825   572        NaN\n",
      "1    1.0  0.000046     2.451272  0.545728  1145        NaN\n",
      "2    2.0  0.000069     0.280404  0.147569  1718        NaN\n",
      "3    3.0  0.000092     0.115689  0.076925  2291        NaN\n",
      "4    4.0  0.000115     0.068876  0.046653  2864        NaN\n"
     ]
    }
   ],
   "source": [
    "# Lee el archivo CSV en un DataFrame de pandas\n",
    "metrics = pd.read_csv(path_metric_csv)\n",
    "\n",
    "# Muestra las primeras filas del DataFrame para verificar la importación\n",
    "print(\"Primeros datos\")\n",
    "print(metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse que los valores de epoch sean número enteros\n",
    "metrics['epoch'] = metrics['epoch'].astype(int)\n",
    "\n",
    "# Encontrar los índices donde test_loss está ausente\n",
    "missing_indices = metrics[metrics['test_loss'].isnull()].index\n",
    "\n",
    "# Eliminar las entradas en las demás columnas correspondientes a los índices de datos faltantes\n",
    "metrics = metrics.drop(missing_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestra de la información procesada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeros datos eliminando filas con datos faltantes\n",
      "    epoch        lr  train_loss  val_loss   step  test_loss\n",
      "10     10  0.000252    0.098040  0.016314   6302   0.097029\n",
      "20     20  0.000400    0.035254  0.006512  12032   0.059656\n",
      "30     30  0.000400    0.023818  0.008792  17762   0.078178\n",
      "40     40  0.000400    0.013053  0.072010  23492   0.262200\n",
      "50     50  0.000400    0.002615  0.002128  29222   0.031002\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame resultante\n",
    "print(\"\\nPrimeros datos eliminando filas con datos faltantes\")\n",
    "print(metrics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultimos datos eliminando filas con datos faltantes\n",
      "     epoch            lr  train_loss  val_loss    step  test_loss\n",
      "650    650  9.671406e-07    0.000004  0.000342  373022   0.006469\n",
      "660    660  7.737125e-07    0.000004  0.000342  378752   0.006446\n",
      "670    670  7.737125e-07    0.000004  0.000341  384482   0.006394\n",
      "680    680  6.189700e-07    0.000005  0.000341  390212   0.006460\n",
      "690    690  6.189700e-07    0.000005  0.000342  395942   0.006409\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame resultante\n",
    "print(\"\\nUltimos datos eliminando filas con datos faltantes\")\n",
    "print(metrics.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfica Learnig Rate en función de las Épocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"imagenes/grafica4.png\" alt=\"lr_vs_epoch_a\" width=\"400\" style=\"margin-right: 10px;\">\n",
    "  <img src=\"imagenes/grafica5.png\" alt=\"lr_vs_epoch_b\" width=\"400\" style=\"margin-right: 10px;\">\n",
    "  <img src=\"imagenes/grafica6.png\" alt=\"lr_vs_epoch_c\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfica MAE en función de las Épocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"imagenes/grafica1.png\" alt=\"MAE_vs_epoch_a\" width=\"400\" style=\"margin-right: 10px;\">\n",
    "  <img src=\"imagenes/grafica2.png\" alt=\"MAE_vs_epoch_b\" width=\"400\" style=\"margin-right: 10px;\">\n",
    "  <img src=\"imagenes/grafica3.png\" alt=\"MAE_vs_epoch_c\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo del dataset que utiliza torchmd-net\n",
    "torchmdnet_dataset = torch.load(path_torchmdnet_dataset)\n",
    "\n",
    "# Cargar archivo splits\n",
    "splits_data = np.load(path_splits_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almacenar datos para ser usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la matriz específica dentro del archivo npz\n",
    "splits = splits_data['idx_test'] \n",
    "\n",
    "# Indexar el dataset con los índices de splits\n",
    "dataset_torchmdnet_test = torchmdnet_dataset[splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el modelo de predicción entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmdnet.models.model import load_model\n",
    "model= load_model(path_trained_model, derivative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar las inferencias de energia y fuerzas y guardarlas en un numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 'inferencias_test.dat' ya existe. No se ha realizado ninguna acción.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('data/inferencias_test.dat'):\n",
    "    with open('data/inferencias_test.dat', 'w') as file:\n",
    "        for molecula in dataset_torchmdnet_test:\n",
    "            z_sample = molecula.z\n",
    "            pos_sample = molecula.pos\n",
    "            n_energy_sample = molecula.y\n",
    "            # Hacer la inferencia\n",
    "            n_energy_inferred, n_forces_inferred = model(z_sample, pos_sample)\n",
    "            # Transformar la inferencia\n",
    "            n_energy_inferred = float(n_energy_inferred)\n",
    "            n_energy_sample = float(n_energy_sample)        \n",
    "            # Guardar los datos en el archivo\n",
    "            file.write(f\"{n_energy_sample} {n_energy_inferred}\\n\")\n",
    "else:\n",
    "    print(\"El archivo 'inferencias_test.dat' ya existe. No se ha realizado ninguna acción.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular metricas de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "La desviación estandar es: 0.016072761509528743\n",
      "\n",
      "El error cuadratico medio es: 0.0002583336625421887\n",
      "\n",
      "La raiz del error cuadratico medio es: 0.016072761509528743\n",
      "\n",
      "El error absoluto medio es: 6.368 meV\n"
     ]
    }
   ],
   "source": [
    "from scripts.error import error\n",
    "\n",
    "data = np.loadtxt('data/inferencias_test.dat')\n",
    "energy_sample = data[:, 0]\n",
    "energy_inferred = data[:, 1]\n",
    "\n",
    "std_error=error(\"std\",\"energy\",energy_sample,energy_inferred)\n",
    "mse_error=error(\"mse\",\"energy\",energy_sample,energy_inferred)\n",
    "rmse_error=error(\"rmse\",\"energy\",energy_sample,energy_inferred)\n",
    "mae_error=error(\"mae\",\"energy\",energy_sample,energy_inferred)\n",
    "mae_error=mae_error*1000\n",
    "\n",
    "print(f\"\\nLa desviación estandar es: {std_error}\")\n",
    "print(f\"\\nEl error cuadratico medio es: {mse_error}\")\n",
    "print(f\"\\nLa raiz del error cuadratico medio es: {rmse_error}\")\n",
    "print(f\"\\nEl error absoluto medio es: {mae_error:.3f} meV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"imagenes/tabla1.jpg\" alt=\"Resultados_Articulo\" width=\"900\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de la arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La arquitectura TorchMD-NET requiere multiples parametros de configuración los cuales se agrupan de la siguiente manera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuración general:**\n",
    "\n",
    "- `--load-model`: Argumento para cargar un modelo desde un punto de control.\n",
    "- `--conf` (`-c`): Especifica un archivo de configuración en formato YAML.\n",
    "- `--num-epochs`: Número de épocas de entrenamiento.\n",
    "- `--batch-size`: Tamaño del lote para el entrenamiento.\n",
    "- `--inference-batch-size`: Tamaño del lote para la inferencia (validación y pruebas).\n",
    "- `--lr`: Tasa de aprendizaje.\n",
    "- `--lr-patience`: Paciencia para el ajuste de la tasa de aprendizaje.\n",
    "- `--lr-metric`: Métrica utilizada para decidir cuándo reducir la tasa de aprendizaje.\n",
    "- `--lr-min`: Tasa de aprendizaje mínima antes de detener el entrenamiento.\n",
    "- `--lr-factor`: Factor para ajustar la tasa de aprendizaje.\n",
    "- `--lr-warmup-steps`: Número de pasos de calentamiento para la tasa de aprendizaje.\n",
    "- `--early-stopping-patience`: Paciencia para detener el entrenamiento si no mejora.\n",
    "- `--reset-trainer`: Restablece las métricas de entrenamiento cuando se carga un punto de control.\n",
    "- `--weight-decay`: Fuerza de la degradación de los pesos.\n",
    "- `--ema-alpha-y`: Factor de influencia de las nuevas pérdidas en el promedio móvil exponencial de `y`.\n",
    "- `--ema-alpha-neg-dy`: Factor de influencia de las nuevas pérdidas en el promedio móvil exponencial de `neg_dy`.\n",
    "- `--ngpus`: Número de GPUs a utilizar.\n",
    "- `--num-nodes`: Número de nodos.\n",
    "- `--precision`: Precisión de punto flotante.\n",
    "- `--log-dir` (`-l`): Directorio para los registros.\n",
    "- `--splits`: Archivo NPZ con divisiones `idx_train`, `idx_val`, `idx_test`.\n",
    "- `--train-size`: Porcentaje/número de muestras en el conjunto de entrenamiento.\n",
    "- `--val-size`: Porcentaje/número de muestras en el conjunto de validación.\n",
    "- `--test-size`: Porcentaje/número de muestras en el conjunto de pruebas.\n",
    "- `--test-interval`: Intervalo de pruebas.\n",
    "- `--save-interval`: Intervalo de guardado de modelos.\n",
    "- `--seed`: Semilla aleatoria.\n",
    "- `--num-workers`: Número de trabajadores para la obtención de datos.\n",
    "- `--redirect`: Redirigir la salida estándar y de error al directorio de registro.\n",
    "- `--gradient-clipping`: Norma de recorte del gradiente.\n",
    "\n",
    "**Configuración de datos y modelo:**\n",
    "\n",
    "- `--dataset`: Nombre del conjunto de datos Torch Geometric.\n",
    "- `--dataset-root`: Directorio de almacenamiento de datos (no utilizado si el conjunto de datos es \"CG\").\n",
    "- `--dataset-arg`: Argumentos adicionales para el conjunto de datos en formato JSON.\n",
    "- `--coord-files`: Glob para archivos de coordenadas personalizados.\n",
    "- `--embed-files`: Glob para archivos de incrustaciones personalizados.\n",
    "- `--energy-files`: Glob para archivos de energía personalizados.\n",
    "- `--force-files`: Glob para archivos de fuerza personalizados.\n",
    "- `--y-weight`: Factor de ponderación para la etiqueta `y` en la función de pérdida.\n",
    "- `--neg-dy-weight`: Factor de ponderación para `neg_dy` en la función de pérdida.\n",
    "\n",
    "**Configuración de la arquitectura del modelo:**\n",
    "\n",
    "- `--model`: Modelo a entrenar.\n",
    "- `--output-model`: Tipo de modelo de salida.\n",
    "- `--prior-model`: Modelo previo a utilizar.\n",
    "- `--charge`: Indica si el modelo necesita una carga total.\n",
    "- `--spin`: Indica si el modelo necesita un estado de espín.\n",
    "- `--embedding-dimension`: Dimensión de la incrustación.\n",
    "- `--num-layers`: Número de capas de interacción en el modelo.\n",
    "- `--num-rbf`: Número de funciones de base radial en el modelo.\n",
    "- `--activation`: Función de activación.\n",
    "- `--rbf-type`: Tipo de expansión de distancia.\n",
    "- `--trainable-rbf`: Si las funciones de expansión de distancia deben ser entrenables.\n",
    "- `--neighbor-embedding`: Si se debe aplicar una incrustación de vecinos antes de las interacciones.\n",
    "- `--aggr`: Operación de agregación para la salida del filtro CFConv.\n",
    "\n",
    "**Configuración específica del Transformer:**\n",
    "\n",
    "- `--distance-influence`: Donde se incluye la información de distancia en la atención.\n",
    "- `--attn-activation`: Función de activación de atención.\n",
    "- `--num-heads`: Número de cabezas de atención.\n",
    "\n",
    "**Otros parámetros:**\n",
    "\n",
    "- `--equivariance-invariance-group`: Grupo de equivarianza e invarianza de TensorNet.\n",
    "- `--derivative`: Si es verdadero, toma la derivada de la predicción con respecto a las coordenadas.\n",
    "- `--cutoff-lower`: Límite inferior en el modelo.\n",
    "- `--cutoff-upper`: Límite superior en el modelo.\n",
    "- `--atom-filter`: Suma solo sobre átomos con `Z > atom_filter`.\n",
    "- `--max-z`: Número atómico máximo que cabe en la matriz de incrustación.\n",
    "- `--max-num-neighbors`: Número máximo de vecinos a considerar en la red.\n",
    "- `--standardize`: Si es verdadero, multiplica la predicción por la desviación estándar del conjunto de datos y agrega la media.\n",
    "- `--reduce-op`: Operación de reducción para predicciones atómicas.\n",
    "- `--wandb-use`: Si se usa Wandb (plataforma de seguimiento de experimentos).\n",
    "- `--wandb-name`: Nombre para la ejecución de Wandb.\n",
    "- `--wandb-project`: Proyecto Wandb al que se registran los experimentos.\n",
    "- `--wandb-resume-from-id`: Reanudar un experimento Wandb a partir de un ID dado.\n",
    "- `--tensorboard-use`: Si se usa TensorBoard (plataforma de seguimiento de experimentos de TensorFlow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de la arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de contenedor docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para instalar el contenedor docker es necesario tener instalado Docker en la computadora. Una vez instalado docker, ejecutamos el siguiente comando en una terminal en el directorio donde estemos trabajando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run -it --gpus all -p 9999:8888 -v $PWD:/workspace --name torchmd-net --shm-size 16G emmanuelzula/servicio:1.3 /bin/bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este comando se utiliza para ejecutar un contenedor Docker con ciertas configuraciones. Aquí está la lista:\n",
    "\n",
    "1. **docker run**: Esto es el comando principal de Docker para ejecutar un contenedor.\n",
    "\n",
    "2. **-it**: Estos son argumentos que se utilizan para indicar que se desea una terminal interactiva. Esto permite interactuar con el contenedor a través de la línea de comandos.\n",
    "\n",
    "3. **--gpus all**: Indica que deseas asignar todos los recursos de GPU disponibles en el contenedor. Esto asume que tienes GPU y que has configurado Docker para admitir GPU.\n",
    "\n",
    "4. **-p 9999:8888**: Esto mapea el puerto 8888 del contenedor al puerto 9999 de tu host local. Significa que si el contenedor ejecuta un servicio en el puerto 8888, podrás acceder a él desde tu navegador en `localhost:9999`.\n",
    "\n",
    "5. **-v $PWD:/workspace**: Este argumento establece un volumen (mount) que vincula el directorio actual (`$PWD`) en tu host local con el directorio `/workspace` en el contenedor. Esto permite compartir archivos y datos entre tu sistema local y el contenedor.\n",
    "\n",
    "6. **--name torchmd-net**: Asigna un nombre al contenedor, en este caso, \"torchmd-net\". Puedes usar este nombre para hacer referencia al contenedor en lugar de su identificador largo.\n",
    "\n",
    "7. **--shm-size 16G**: Esto configura el tamaño de la memoria compartida (shared memory) dentro del contenedor en 16 gigabytes. Algunas aplicaciones pueden requerir más memoria compartida.\n",
    "\n",
    "8. **emmanuelzula/servicio:1.3**: Es la imagen de Docker que se utilizará para crear el contenedor. En este caso, se está utilizando la imagen \"emmanuelzula/servicio\" con la etiqueta \"1.3\".\n",
    "\n",
    "9. **/bin/bash**: Es el comando que se ejecutará dentro del contenedor. En este caso, se inicia un shell Bash dentro del contenedor, lo que te permite interactuar con él."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que termine de descargar e instalar el contenedor, por defecto estaremos dentro de él en la carpeta /workspace. Para salir del contenedor escribimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "exit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para detener el contenedor escribimos en la terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker stop torchmd-net\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso del contenedor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero debemos iniciar el contenedor con el siguiente comando en terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker start torchmd-net\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez iniciado accedemos a él con el comando en terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker exec -it torchmd-net /bin/bash/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto estaremos dentro de la carpeta del contenedor \"/workspace\" y con el ambiente virtual mamba \"torchmd-net\" activado. El el ambiente virtual se encuentara instaladas todas las dependencias, modulos y la arquitectura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente se puede ejecutar jupyter notebook con el siguiente comando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "jupyter notebook --ip='0.0.0.0' --port=8888 --no-browser --allow-root\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que el el puerto 8888 del contenedor se muestra en el puerto 9999 de la compuradora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución de la arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La arquitectura requiere de: una carpeta de input, una carpeta de output y un script de arranque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En la carpeta input debera estar el archivo de configuración con extensión .yaml que debera contener toda la configuración de la arquitectura.\n",
    "* En la carteta output se guardaran todos los resultados del entrenamiento.\n",
    "* En el script de arranque deberan estar las instrucciónes de inicio y debera tener la estructura del siguiente ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=1,2,3 torchmd-train --conf nuevos-entrenamientos/ET-QM9.yaml --log-dir qm9/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cual configura los siguiente parametros de la forma:\n",
    "\n",
    "- `CUDA_VISIBLE_DEVICES=1,2,3`: Este comando establece las GPU visibles para el proceso. En este caso, se configura para usar las GPU con identificadores 1, 2 y 3. Esto significa que el entrenamiento se realizará en estas tres GPU si están disponibles.\n",
    "\n",
    "- `torchmd-train`: Este es el comando principal que se ejecuta. Parece ser una herramienta específica o un script de entrenamiento relacionado con TorchMD.\n",
    "\n",
    "- `--conf nuevos-entrenamientos/ET-QM9.yaml`: Este es un argumento que proporciona la ruta al archivo de configuración YAML `ET-QM9.yaml` ubicado en el directorio `nuevos-entrenamientos`.\n",
    "\n",
    "- `--log-dir qm9/`: Este argumento especifica el directorio donde se guardarán los registros del entrenamiento. En este caso, los registros se guardarán en un directorio llamado `qm9/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso con nohup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opcionalmente se ejecutar el script de forma independiente a la terminal, esto permite cerrar la terminal sin terminar el proceso iniciado por el script. Para hacerlo utilizamos nohup con el siguiente comando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "CUDA_VISIBLE_DEVICES=1,2,3 nohup torchmd-net_qm9.sh > output.out &\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchmd-net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
